\chapter{GenAI}


% ---------- Perplexity ----------
\clearpage
\thispagestyle{genaistyle}
\section{Perplexity}
\subsection{Perplexity}

% reference:
% https://aclanthology.org/2021.deelio-1.5.pdf
% https://kilthub.cmu.edu/articles/journal_contribution/Evaluation_Metrics_For_Language_Models/6605324/1?file=12095765
% https://huggingface.co/docs/transformers/perplexity
% https://brenocon.com/blog/2013/01/perplexity-as-branching-factor-as-shannon-diversity-index/

Perplexity is a widely used metric for evaluating language models. At its core, perplexity measures how well a probability distribution or model
predicts a sample. Mathematically, it is defined as the exponential of the average negative log-likelihood of the sequence. Intuitively, you can
think of it as the “average branching factor” — the number of equally likely choices the model considers at each step.

% equation
\begin{center}
    FORMULA GOES HERE
\end{center}

A lower perplexity indicates that the model assigns higher probabilities to the observed text, meaning it is less “surprised”.

\textbf{When to use Perplexity?}

Perplexity is most commonly used when evaluating language models during training or benchmarking. It helps track how well a model fits text data and
is especially useful for comparing models trained on the same dataset. However, perplexity is best suited for probabilistic next-token prediction
tasks and less reliable as a direct measure of end-user text quality.

\coloredboxes{
\item Simple and interpretable. Lower perplexity values generally mean better predictive performance.
\item Efficient for training evaluation. It provides a direct signal for model optimization without requiring human evaluation.
}
{
\item Models with low perplexity may still generate incoherent or unhelpful text.
\item Sensitive to tokenization and normalization choices.
\item Not well-defined for masked language models. Architectures like BERT predict missing tokens rather than generating sequences left-to-right,
making perplexity unsuitable for evaluating them.
}

\clearpage

\thispagestyle{customstyle}

\orangebox{Did you know that...}
{Perplexity is closely related to entropy in information theory. In fact, $Perplexity = 2^{H(P)}$
where \(H(P)\) is the entropy. This means that perplexity can be seen as the effective 
number of equally likely words the model is choosing from at each step!}

% ---------- BERTScore ----------
\clearpage
\thispagestyle{genaistyle}
\section{BERTScore}
\subsection{BERTScore}

% reference:
% https://arxiv.org/pdf/1904.09675
% https://wiki.math.uwaterloo.ca/statwiki/index.php?title=BERTScore:_Evaluating_Text_Generation_with_BERT

BERTScore is a metric for evaluating text generation that leverages contextual embeddings from pre-trained language models like BERT.
Instead of relying solely on surface-level n-gram overlap (as in BLEU or ROUGE), BERTScore computes similarity by aligning tokens from the
candidate and reference sentences in embedding space.

% equation
\begin{center}
    FORMULA GOES HERE
\end{center}

Mathematically, for each token in a candidate sentence, BERTScore finds its most similar token in the reference sentence (and vice versa)
using cosine similarity. Precision, recall, and F1 are then aggregated over all pairs, yielding a semantic-oriented score that correlates
strongly with human judgments.

\textbf{When to use the BERTScore?}

Use BERTScore when evaluating tasks where semantic similarity matters more than exact wording, such as machine translation, summarization, or
dialogue generation. It is especially useful when generated text can be phrased differently from references but still convey the same meaning.

\coloredboxes{
\item Context-aware. Uses deep contextual embeddings, capturing meaning beyond surface word matches
\item Better correlation with humans. Empirical studies show BERTScore aligns more closely with human evaluation than BLEU or ROUGE.
}
{
\item Computationally heavy. Requires embedding extraction with large pre-trained models, making it slower than n-gram metrics.
\item Model dependence. Performance varies depending on which pre-trained model (e.g., BERT, RoBERTa, multilingual-BERT) is used.
\item Bias inheritance. Any biases in the underlying language model embeddings can influence the scores.
}

\clearpage

\thispagestyle{customstyle}

\orangebox{Did you know that...}
{The original BERTScore paper included a picture of Bert from Sesame Street paying homage to the model’s namesake and adding a playful touch to an
otherwise technical paper.}