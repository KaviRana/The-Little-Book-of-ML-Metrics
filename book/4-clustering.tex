\chapter{Clustering}


% ---------- Mutual Info Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Mutual Info Score}
\subsection{Mutual Info Score}

% ---------- adjusted mutual info score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Adjusted Mutual Info score}
\subsection{Adjusted Mutual Information score}

% ---------- Normalized Mutual Info Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Normalized Mutual Info Score}
\subsection{Normalized Mutual Info Score}

% ---------- rand score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Rand Score}
\subsection{Rand Score}

% ---------- adjusted rand score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Adjusted Rand Score}
\subsection{Adjusted Rand Score}

% ---------- calinski harabasz score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{CH Score}
\subsection{Calinski Harabasz Score}


% ---------- contingency matrix ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Contingency Matrix}
\subsection{Contingency Matrix}

% ---------- pair confusion matrix ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Pair Confusion Matrix}
\subsection{Pair Confusion Matrix}

% ---------- Completeness Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Completeness Score}
\subsection{Completeness Score}

% ---------- Davies Bouldin Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Davies Bouldin Score}
\subsection{Davies Bouldin Score}

The Davies-Bouldin score measures the quality of clustering by evaluating the average similarity between each cluster \( C_i \) and its most similar neighboring cluster 
\( C_j \) for $i,j = 1, 2, ... k$. This similarity \( R_{ij} \) is calculated as the ratio of the within-cluster distance (how tightly packed the cluster is) to the between-cluster distance (how far apart the clusters are).

% The Davies Bouldin score is the average similairty measure of each cluster $C_{i}$ for $i = 1,2,...k$  with its most similar cluster $C_{j}$, where similarity $R_{ij}$ is the ratio of within-cluster distances to between cluster distance. So the clusters which are farther apart and less dispersed will result in a better score. The Davis Bouldin index is defined as 

\begin{center}
    \tikz{
    \node[inner sep=2pt, font=\Large] (a) {
    {
    $\displaystyle
    DB = \frac{1}{k} \sum_{{\color{nmlpurple}i}=1}^{k} \max_{{\color{nmlpurple}i} \neq {\color{cyan}j}} R_{{\color{nmlpurple}i}{\color{cyan}j}}
    $
    }
    }; 
    }
% \end{center}

% \begin{center}
    \tikz{
    \node[inner sep=2pt, font=\Large] (a) {
    {
    $\displaystyle
    R_{{\color{nmlpurple}i}{\color{cyan}j}} = \frac{s_{\color{nmlpurple}i} + s_{\color{cyan}j}}{d_{\color{nmlpurple}i\color{cyan}j}}
    $
    }
    }; 
    \draw[-latex,nmlpurple, semithick] ($(a.north)+(1.2,0.05)$) to[bend left=15] node[pos=1, right] {cluster diameter} +(1,.5); 
    \draw[-latex,cyan, semithick] ($(a.south)+(0.6,-0.05)$) to[bend left=15] node[pos=1, left] {distance between centroids} +(-1,-.5); 
    }
\end{center}

% A lower Davies-Bouldin score indicates better clustering, as it suggests that clusters are more compact and well-separated from one another.
% where $s_{i}$ is the average distance between each point of cluster $i$ and centroid of that cluster and $d_{ij}$ is the distance between cluster centroids $i$ and $j$. The minium Davies Bouldin score is zero, with lower values indicating better clustering.

Here, \( s_i \) represents the average distance between each point in cluster \( i \) and the centroid of that cluster, while \( d_{ij} \) is the distance between the centroids of clusters \( i \) and \( j \). The Davies-Bouldin score has a minimum value of zero, with lower scores indicating better-defined clusters that are compact and well-separated.

\textbf{When to use Davies Bouldin?}

Use Davies Bouldin Score when the ground truth labels are unknown and the evaluation must be performed using the model itself.

\coloredboxes{
\item The computation of Davies-Bouldin is simpler than that of Silhouette scores, zero is the lowest possible score and closer the value to zero indicate a better separation.
}
{
\item Davies Bouldin Score can generally be higher for convex clusters than other clusters, such as density based clusters.
\item The usage of centroid distance limits the distance metric to Euclidean space.
}

% ---------- Fowlkes Mallows Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Fowlkes Mallows Score}
\subsection{Fowlkes Mallows Score}

% ---------- Homogeneity Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Homogeneity Score}
\subsection{Homogeneity Score}

% ---------- V Measure ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{V Measure}
\subsection{V Measure}

% ---------- Homogeneity Completeness V Measure ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Homogeneity Completeness V Measure}
\subsection{Homogeneity Completeness V Measure}

% ---------- Silhouette Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{Silhouette Score}
\subsection{Silhouette Score}

The Silhouette Coefficient measures how well a data point fits within its assigned cluster compared to other clusters. 
It quantifies how similar a sample is to its own cluster (cohesion) compared to the nearest neighboring cluster (separation).
The Silhouette Coefficient $s(i)$ for a given data point $i$ in the cluster $C_I$, where $|C_I|$ is the number of data points in $C_I$, is given by:

\begin{center}
\tikz{
\node[inner sep=2pt, font=\Large] (a) {
{
$\displaystyle
s(i) = 
\begin{cases}
\frac{{\color{cyan}b(i)} - {\color{nmlpurple}a(i)}}{max\left\{ {\color{nmlpurple}a(i)}, {\color{cyan}b(i)} \right\}}  & if\, |C_I| > 1 \\
0  & if\, |C_I| = 1
\end{cases}
$
}
};
\draw[-latex,cyan, semithick] ($(a.north)+(-0.9,0.05)$) to[bend right=15] node[pos=1, left] {measures cohesion} +(-1,.5); 
\draw[-latex,nmlpurple, semithick] ($(a.north)+(0.2,0.05)$) to[bend left=15] node[pos=1, right] {measures separation} +(1,.5); 
% \draw[-latex,nmlpurple, semithick] ($(b.north)+(0.1,0.05)$) to[bend left=15] node[pos=1, left] {True negatives} +(-1,-.5); 
}
\end{center}

Where  $a(i)$ is the mean distance between a sample and all other points in the same cluster (mean intra-cluster distance), 
and  $b(i)$ is the mean distance between a sample and all points in the nearest different cluster (mean nearest-cluster distance). 
The value of  $s(i)$ lies between -$1$ and  $1$, where  $s(i) \approx 1$ indicates that the data point is well-clustered, 
 $s(i) \approx 0$ means the data point is on or very close to the boundary between two clusters, and  $s(i) \approx -1$ 
suggests that the data point has been misclassified into the wrong cluster.

\textbf{When to use Silhouette Score?}

Use Silhouette Score when the ground truth labels are unknown and the evaluation must be performed using the model itself.

\coloredboxes{
\item It provides a clear and intuitive measure of how well clusters are separated, +1 highly dense and -1 for incorrect clustering.
}
{
\item Silhouette Score can generally be higher for convex clusters than other clusters, such as density based clusters.
\item Higher Silhouette Score doesn't necessarily indicate that the clusters will have equal sizes; the clusters can still vary in cardinality. 
}

% ----------  Consensus Score ----------
\clearpage
\thispagestyle{clusteringstyle}
\section{ Consensus Score}
\subsection{ Consensus Score}