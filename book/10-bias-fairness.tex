\chapter{Bias \& Fairness}


% ---------- Demographic Parity ----------
\clearpage
\thispagestyle{biasfairnesstyle}
\section{Demographic Parity}
\subsection{Demographic Parity}

% reference:
% https://developers.google.com/machine-learning/crash-course/fairness/demographic-parity
% https://afraenkel.github.io/fairness-book/content/05-parity-measures.html#demographic-parity
% https://fairmlbook.org/classification.html

Demographic Parity (also known as Statistical Parity) is one of the most widely cited fairness metrics in machine learning.
It requires that the decision of a model be independent of a protected attribute (such as gender, race, or age). In other words,
the probability of receiving a positive prediction should be the same across groups, regardless of whether the prediction is correct.

% Formula
\begin{center}
    % P(Y^=1∣A=a)=P(Y^=1∣A=b)∀a,b
    FORMULA GOES HERE
\end{center}

A model satisfies demographic parity if members of different demographic groups are selected at equal rates. For example, in a loan approval
system, demographic parity would mean that the proportion of approved applications is the same across groups, independent of creditworthiness.

\textbf{When to use Demographic Parity?}

Use demographic parity when the fairness objective is equal treatment across groups in terms of outcomes, even if this comes at the cost
of predictive accuracy. It is often applied in contexts such as hiring, lending, or college admissions, where ensuring equal access is a
primary concern.

\coloredboxes{
\item Simple to compute and easy to explain to non-technical stakeholders.
\item Guarantees equal selection rates across groups, supporting inclusion.
}
{
\item It only looks at whether groups get the same share of positive outcomes, but not at whether those predictions are actually correct.
\item Can reduce overall model accuracy if the underlying distributions differ.
}

\clearpage

\thispagestyle{customstyle}

\orangebox{Did you know that...}
{Demographic parity goes by several other names in the literature, often referred to as statistical parity, group fairness, or even
independence criterion. Different research communities picked different terms, but they all describe the same idea.}


% ---------- Equality of Opportunity ----------
\clearpage
\thispagestyle{biasfairnesstyle}
\section{Equality of Opportunity}
\subsection{Equality of Opportunity}

Equality of Opportunity is a fairness metric that focuses on ensuring that individuals who truly belong to the positive class
(e.g., qualified applicants) have an equal chance of being correctly identified across different demographic groups.
Formally, the metric requires that the True Positive Rate (TPR) be equal across groups.

% Formula
\begin{center}
    % P(Y^=1∣Y=1,A=a)=P(Y^=1∣Y=1,A=b)
    FORMULA GOES HERE
\end{center}

In other words, if two people are equally qualified, their chance of being recognized as such by the model should not depend on their
demographic group.

\textbf{When to use Equality of Opportunity?}

This metric is particularly useful in high-stakes scenarios where false negatives carry large consequences, such as university admissions,
medical diagnoses, or loan approvals. It ensures that qualified individuals are treated equally, regardless of group membership.

\coloredboxes{
\item Ensures qualified individuals have equal chances across groups, even if overall acceptance rates differ.
\item Models can vary in their ratio of positive to negative predictions across groups, as long as the true positives are treated fairly.
\item Can be more aligned with fairness in practical scenarios, where ensuring equal opportunity for qualified candidates
is more meaningful than enforcing equal acceptance rates.
}
{
\item Only applies when there is a clearly preferred label (e.g., “qualified”), limiting its use to such contexts.
\item Does not guarantee fairness for the negative class, unlike metrics such as Equalized Odds.
\item Requires demographic group labels to compare outcomes. If group membership is unavailable, the metric cannot be applied.
}

\clearpage

\thispagestyle{customstyle}

\orangebox{Did you know that...}
{Equality of Opportunity was popularized in the 2016 paper “Equality of Opportunity in Supervised Learning” by Hardt, Price, and Srebro. 
In that paper, they introduced both Equality of Opportunity and its stricter sibling, Equalized Odds. The terms have since become standard
in the fairness in ML literature.}

% ---------- Equality of Odds ----------
\clearpage
\thispagestyle{biasfairnesstyle}
\section{Equality of Odds}
\subsection{Equality of Odds}

% resources:
% https://arxiv.org/pdf/1610.02413
% https://mlu-explain.github.io/equality-of-odds/

Equality of Odds is a fairness metric that requires a model to have equal true positive rates (TPR) and equal false positive rates (FPR)
across different demographic groups. In other words, the model should be equally good at identifying positives and equally bad at making mistakes,
no matter which group an individual belongs to.

% Formula
\begin{center}
    % P(Y^=1∣Y=y,A=a)=P(Y^=1∣Y=y,A=b)∀y∈{0,1},a,b∈A
    FORMULA GOES HERE
\end{center}

Equalized Odds is stricter than Equality of Opportunity, which only enforces equality on the true positive rate. If we relax the Equalized Odds
condition to focus only on the case where $Y = 1$, we obtain the Equality of Opportunity formula.

\textbf{When to use Equality of Odds?}

Use Equality of Odds when both types of classification errors, false positives and false negatives, carry important consequences.
For example, in loan approvals, we want to ensure that different groups are not only equally likely to receive a loan when they are
truly creditworthy, but also equally likely to be mistakenly given a loan when they are not.

\coloredboxes{
\item Captures fairness across both positive and negative outcomes.
\item More comprehensive than Equality of Opportunity, which only balances true positive rates.
}
{
\item May be difficult or impossible to satisfy perfectly, especially when the distribution of labels differ across groups.
\item Enforcing Equality of Odds can reduce overall model accuracy, creating a trade-off between fairness and performance.
}

\clearpage

\thispagestyle{customstyle}

\orangebox{Did you know that...}
{Equality of Odds was popularized in the 2016 paper “Equality of Opportunity in Supervised Learning” by Hardt, Price, and Srebro. 
In that paper, they introduced both Equality of Odds and its less stricter sibling, Equality Opportunity. The terms have since become standard
in the fairness in ML literature.}

% For second page we can follow The ROC Curves example of this resource: https://mlu-explain.github.io/equality-of-odds/

% ---------- Predictive Parity ----------
\clearpage
\thispagestyle{biasfairnesstyle}
\section{Predictive Parity}
\subsection{Predictive Parity}

references:
% https://fairware.cs.umass.edu/papers/Verma.pdf
% https://njoselson.github.io/pdfs/ProPublica_Commentary_Final_070616.pdf
% https://afraenkel.github.io/fairness-book/content/05-parity-measures.html#predictive-value-parity-ppv-parity-and-npv-parity

Predictive Parity, also known as predictive value parity or the outcome test, is a fairness metric that checks whether a model’s precision 
(positive predictive value, PPV) is the same across different demographic groups. In simple terms, if a model predicts that someone belongs to
the positive class (e.g., “approved for a loan”), Predictive Parity requires that the probability of this prediction being correct is equal for
all groups.

% Formula
\begin{center}
    % P(Y=1∣Y^=1,A=a)=P(Y=1∣Y^=1,A=b)
    FORMULA GOES HERE
\end{center}

If predictive parity holds, then the false discovery rate (FDR) will also be equal across groups, since $FDR = 1 − PPV$.

\textbf{When to use Predictive Parity?}

Predictive Parity is most relevant when the cost of false positives is high, and we care about ensuring that predicted positives are equally
reliable across groups. For example, in credit scoring, it ensures that an approved loan is equally likely to be repaid whether the applicant
belongs to one demographic group or another.

\coloredboxes{
\item Ensures the same fraction of correct positive predictions across groups.
\item Easy to interpret: it directly extends the familiar concept of precision.
}
{
\item Incompatible with other fairness metrics (such as equalized odds) when base rates differ across groups. It is mathematically
impossible to satisfy both simultaneously.
\item Equal PPVs can hide differences in false negative rates or access to positive outcomes.
}

\clearpage

\thispagestyle{customstyle}

\orangebox{Did you know that...}
{Predictive parity gained attention during the debate around the COMPAS recidivism tool. ProPublica’s 2016 investigation argued that COMPAS was
unfair because it did not satisfy equalized odds, while its developers countered that the tool did satisfy predictive parity, illustrating how
different fairness definitions can conflict and fuel controversy.}